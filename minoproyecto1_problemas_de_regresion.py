# -*- coding: utf-8 -*-
"""Minoproyecto1_Problemas de Regresion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WwmInu1-uNgr-7WJ7h040aGhzv82EgKy
"""

# Punto 1-7: Importar librerías
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from scipy.stats import shapiro
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LinearRegression, Lasso, Ridge
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error
import joblib

print("Librerías importadas correctamente.")

"""# **PUNTO #1: Escoger un dataset de los presentados, si tienen alguno propio debe pasar por consulta previa.**

R// Dataset escogido
Concrete Compressive Strength Data Set
https://archive.ics.uci.edu/ml/datasets/Concrete+Compressive+Strength



"""

# Cargar el dataset y verificar columnas
df = pd.read_excel('/content/Concrete_Data.xls')

# Limpiar nombres de columnas para evitar espacios o caracteres invisibles
df.columns = [col.strip() for col in df.columns]

# Verificar nombres de columnas
print("Columnas del dataset:")
for col in df.columns:
    print(f"- {col}")

# Confirmar que las columnas esperadas existen
expected_columns = [
    'Cement (component 1)(kg in a m^3 mixture)',
    'Blast Furnace Slag (component 2)(kg in a m^3 mixture)',
    'Fly Ash (component 3)(kg in a m^3 mixture)',
    'Water  (component 4)(kg in a m^3 mixture)',
    'Superplasticizer (component 5)(kg in a m^3 mixture)',
    'Coarse Aggregate  (component 6)(kg in a m^3 mixture)',
    'Fine Aggregate (component 7)(kg in a m^3 mixture)',
    'Age (day)',
    'Concrete compressive strength(MPa, megapascals)'
]
missing_cols = [col for col in expected_columns if col not in df.columns]
if missing_cols:
    raise ValueError(f"Columnas faltantes: {missing_cols}")
else:
    print("Todas las columnas esperadas están presentes.")

# Mostrar primeras filas
df.head()

"""# **PUNTO #2: Primero realizar un análisis univariado y/o multivariado de las diferentes características estimadoras**"""

# Valores nulos
print("Valores nulos por columna:")
print(df.isna().sum())

# Tipos de datos
print("\nInformación del DataFrame:")
df.info()

# Identificar columnas numéricas y categóricas
num_cols = [c for c in df.columns if df[c].dtype in ['int64', 'float64']]
cat_cols = [c for c in df.columns if df[c].dtype == 'object']
print("\nColumnas numéricas:", num_cols)
print("Columnas categóricas:", cat_cols)

# Registros duplicados
print("\nRegistros Duplicados (antes):", df[df.duplicated()].shape[0])
df.drop_duplicates(inplace=True)
print("Registros Duplicados (después):", df[df.duplicated()].shape[0])

# Estadísticas descriptivas
print("\nEstadísticas descriptivas:")
print(df.describe())

# Análisis univariado: Verificar si los datos tienen una forma específica, conocer como es su distribución, si hay valores atípicos,
#y si son normales con la Shaphiro (menor a 0.05 los datos no son normales)

# Histogramas y boxplots para variables numéricas
fig, ax = plt.subplots(2, len(num_cols), figsize=(5 * len(num_cols), 10))
for i, c in enumerate(num_cols):
    sns.histplot(df[c], kde=True, ax=ax[0, i])
    ax[0, i].set_title(c)
    sns.boxplot(y=df[c], ax=ax[1, i])
    ax[1, i].set_title(c)
plt.tight_layout()
plt.show()

# Prueba de normalidad (Shapiro-Wilk)
print("\nPruebas de normalidad (Shapiro-Wilk):")
for c in num_cols:
    stat, p = shapiro(df[c])
    print(f"{c}: p-valor = {p:.4f} {'(no normal)' if p < 0.05 else '(normal)'}")

# Análisis multivariado: Verificar como las variables están relacionadas entre si.

# Matriz de correlación
plt.figure(figsize=(10, 8))
sns.heatmap(df.corr(), cmap="BrBG", annot=True, fmt='.2f', cbar=False)
plt.title("Matriz de Correlación")
plt.show()

# Pairplot para variables más correlacionadas con la variable objetivo
pairplot_cols = [
    'Cement (component 1)(kg in a m^3 mixture)',
    'Age (day)',
    'Water  (component 4)(kg in a m^3 mixture)',
    'Concrete compressive strength(MPa, megapascals)'
]

# Verificar que todas las columnas existen
if all(col in df.columns for col in pairplot_cols):
    sns.pairplot(df[pairplot_cols], hue='Concrete compressive strength(MPa, megapascals)', height=1.5)
    plt.show()
else:
    print("Error: Algunas columnas no están en el DataFrame:", [col for col in pairplot_cols if col not in df.columns])
    # Alternativa: Gráficos de dispersión con matplotlib
    plt.figure(figsize=(12, 8))
    for i, col in enumerate(pairplot_cols[:-1], 1):
        plt.subplot(2, 2, i)
        plt.scatter(df[col], df['Concrete compressive strength(MPa, megapascals)'], alpha=0.5)
        plt.xlabel(col)
        plt.ylabel('Strength (MPa)')
    plt.tight_layout()
    plt.show()

"""# **PUNTO #3: Realizar la ingeniería de características (conversión de variables categóricas a numéricas, cambio de distribución a la variable, Creación de nuevas variables, Selección de variables) si se requiere para determinar cuáles son la más idóneas para el proceso de regresión. Escoger al menos tres variables estimadoras o más del dataset para obtener una salida. En caso de elegir menos, argumentar sólidamente el porqué de esta decisión.**"""

# Modificación de los datos para los modelos

# Transformar variable sesgada (Age)
df['Age_log'] = np.log1p(df['Age (day)'])

# Visualizar transformación
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
sns.histplot(df['Age (day)'], kde=True)
plt.title('Age (Original)')
plt.subplot(1, 2, 2)
sns.histplot(df['Age_log'], kde=True)
plt.title('Age (Log-Transformed)')
plt.show()

# Crear nueva variable: relación agua/cemento
df['Water_Cement_Ratio'] = df['Water  (component 4)(kg in a m^3 mixture)'] / df['Cement (component 1)(kg in a m^3 mixture)']

# Verificar normalidad y correlación para elegir entre Age y Age_log
p_orig, p_log = shapiro(df['Age (day)'])[1], shapiro(df['Age_log'])[1]
print(f"Age (original) p-valor: {p_orig:.4f}, Age_log p-valor: {p_log:.4f}")

# Calcular correlación con la variable objetivo
corr_orig = df['Age (day)'].corr(df['Concrete compressive strength(MPa, megapascals)'])
corr_log = df['Age_log'].corr(df['Concrete compressive strength(MPa, megapascals)'])
print(f"Correlación Age (original): {corr_orig:.4f}, Age_log: {corr_log:.4f}")

# Seleccionar variable basada en correlación
if abs(corr_log) > abs(corr_orig):
    print("Variable seleccionada: Age_log (mayor correlación)")
    age_selected = 'Age_log'
else:
    print("Variable seleccionada: Age (day) (correlación similar o menor)")
    age_selected = 'Age (day)'

# Eliminar alta colinealidad
correlacion = df.corr().abs()
upper_tri = correlacion.where(np.triu(np.ones(correlacion.shape), k=1).astype(bool))
to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.8)]
print("Columnas eliminadas por alta colinealidad:", to_drop)
df_cleaned = df.drop(columns=to_drop)

# Eliminar columnas con varianza cero
eliminadas = df_cleaned.columns[df_cleaned.nunique() == 1].tolist()
print("Columnas eliminadas por varianza cero:", eliminadas)
df_cleaned = df_cleaned.loc[:, df_cleaned.nunique() > 1]

# Seleccionar las 3 variables más correlacionadas con la variable objetivo
target = 'Concrete compressive strength(MPa, megapascals)'
corr_with_target = df_cleaned.corr()[target].abs().sort_values(ascending=False)
selected_features = corr_with_target[1:4].index.tolist()  # Top 3 (excluyendo la variable objetivo)
print("Variables seleccionadas:", selected_features)

# Asegurar que Age_log se use si fue seleccionado
if age_selected == 'Age_log' and 'Age (day)' in selected_features and 'Age_log' not in selected_features:
    selected_features = [f if f != 'Age (day)' else 'Age_log' for f in selected_features]
    print("Variables ajustadas (usando Age_log):", selected_features)

X = df_cleaned[selected_features]
y = df_cleaned[target]

"""# **PUNTO #4: Dividir el dataset en dos partes, una para la obtención del modelo y otra para las pruebas.**"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print("Tamaño entrenamiento:", X_train.shape)
print("Tamaño prueba:", X_test.shape)

"""# **PUNTO #5: Realizar la estimación de los parámetros de la regresión por los siguientes métodos:**#

* Regresión Lineal (scikit-learn).
* Regularización Lasso
* Regularización Ridge
* SVR
* Incluir alguno de estos dos: Árboles de decisión o KNN

Para los casos de Ridge, Lasso, SVR, y alguno de los dos últimos,
hacer la respectiva selección de hiperparámetros (esto antes de entrenar los modelos).
"""

# Ajusta las variables (como cemento, edad, agua) para que tengan la misma escala (como si todas estuvieran en una escala de 0 a 1).
# Funciona mejor si todas las variables tienen la misma escala, porque variables con números grandes podrían dominar sobre variables pequeñas

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Guardar el escalador
joblib.dump(scaler, 'scaler.joblib')
print("Datos estandarizados y escalador guardado.")

# Inspeccionar las columnas del escalador
import joblib
scaler = joblib.load('scaler.joblib')
print("Columnas vistas por el escalador:", scaler.feature_names_in_)

# Definir modelos
models = {
    'LinearRegression': LinearRegression(),
    'Lasso': Lasso(),
    'Ridge': Ridge(),
    'SVR': SVR(),
    'DecisionTree': DecisionTreeRegressor(random_state=42)
}

# Hiperparámetros para GridSearchCV
param_grids = {
    'Lasso': {'alpha': [0.01, 0.1, 1, 10]},
    'Ridge': {'alpha': [0.01, 0.1, 1, 10]},
    'SVR': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']},
    'DecisionTree': {'max_depth': [3, 5, 10], 'min_samples_leaf': [1, 5, 10]}
}

# Entrenar y optimizar modelos
best_models = {}
for name, model in models.items():
    if name in param_grids:
        grid = GridSearchCV(model, param_grids[name], cv=5, scoring='neg_mean_squared_error')
        grid.fit(X_train_scaled, y_train)
        best_models[name] = grid.best_estimator_
        print(f"Mejores hiperparámetros para {name}: {grid.best_params_}")
    else:
        model.fit(X_train_scaled, y_train)
        best_models[name] = model
    print(f"Modelo {name} entrenado.")

"""# **PUNTO #6: Calcular el error de las predicciones para el conjunto de entrenamiento y el de pruebas**#"""

# Compara las predicciones de cada modelo con los valores reales

def mean_absolute_percentage_error(y_true, y_pred):
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

results = []
for name, model in best_models.items():
    y_train_pred = model.predict(X_train_scaled)
    y_test_pred = model.predict(X_test_scaled)

    metrics = {
        'Model': name,
        'R2_train': r2_score(y_train, y_train_pred),
        'R2_test': r2_score(y_test, y_test_pred),
        'MAE_train': mean_absolute_error(y_train, y_train_pred),
        'MAE_test': mean_absolute_error(y_test, y_test_pred),
        'RMSE_train': np.sqrt(mean_squared_error(y_train, y_train_pred)),
        'RMSE_test': np.sqrt(mean_squared_error(y_test, y_test_pred)),
        'MAPE_train': mean_absolute_percentage_error(y_train, y_train_pred),
        'MAPE_test': mean_absolute_percentage_error(y_test, y_test_pred)
    }
    results.append(metrics)

results_df = pd.DataFrame(results)
print("\nResultados de Evaluación:")
print(results_df)

# Guardar el mejor modelo (basado en R2_test)
best_model_name = results_df.loc[results_df['R2_test'].idxmax(), 'Model']
joblib.dump(best_models[best_model_name], 'best_model.joblib')
print(f"Mejor modelo guardado: {best_model_name}")

"""# **PUNTO #7: Calcular y comparar las métricas R2, MAE, RMSE y MAPE de los modelos obtenidos con los datos de entrenamiento y prueba**"""

# Datos de entrenamiento
min_val = min(y_train.min(), min([model.predict(X_train_scaled).min() for model in best_models.values()]))
max_val = max(y_train.max(), max([model.predict(X_train_scaled).max() for model in best_models.values()]))

fig = go.Figure()
colors = ['blue', 'cyan', 'green', 'red', 'gold']
for i, (name, model) in enumerate(best_models.items()):
    y_pred = model.predict(X_train_scaled)
    fig.add_trace(go.Scatter(x=y_train, y=y_pred, mode='markers', name=name,
                             marker=dict(color=colors[i], opacity=0.6)))
fig.add_trace(go.Scatter(x=[min_val, max_val], y=[min_val, max_val], mode='lines', name='Ideal',
                         line=dict(color='black', dash='dash')))
fig.update_yaxes(range=[min_val, max_val])
fig.update_xaxes(range=[min_val, max_val])
fig.update_layout(title="Rendimiento: Training",
                  xaxis_title="Resistencia Real (MPa)",
                  yaxis_title="Resistencia Predicha (MPa)")
fig.show()

# Datos de prueba
min_val = min(y_test.min(), min([model.predict(X_test_scaled).min() for model in best_models.values()]))
max_val = max(y_test.max(), max([model.predict(X_test_scaled).max() for model in best_models.values()]))

fig = go.Figure()
for i, (name, model) in enumerate(best_models.items()):
    y_pred = model.predict(X_test_scaled)
    fig.add_trace(go.Scatter(x=y_test, y=y_pred, mode='markers', name=name,
                             marker=dict(color=colors[i], opacity=0.6)))
fig.add_trace(go.Scatter(x=[min_val, max_val], y=[min_val, max_val], mode='lines', name='Ideal',
                         line=dict(color='black', dash='dash')))
fig.update_yaxes(range=[min_val, max_val])
fig.update_xaxes(range=[min_val, max_val])
fig.update_layout(title="Rendimiento: Test",
                  xaxis_title="Resistencia Real (MPa)",
                  yaxis_title="Resistencia Predicha (MPa)")
fig.show()

# Distribución de errores
fig_err = go.Figure()
for name, model in best_models.items():
    y_pred = model.predict(X_test_scaled)
    errors = y_test - y_pred
    fig_err.add_trace(go.Histogram(x=errors, name=name))
fig_err.update_layout(title="Comportamiento de los Errores: Test",
                     xaxis_title="Error de Pronóstico (MPa)")
fig_err.show()

# Conclusión
print(f"Mejor modelo: {best_model_name} con R2_test = {results_df['R2_test'].max():.4f}")

# Selección de hiperparámetros con GridSearchCV

# Estandarización
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Ridge
ridge_params = {'alpha': [0.01, 0.1, 1, 10, 100]}
ridge_grid = GridSearchCV(Ridge(), ridge_params, cv=5, scoring='neg_mean_squared_error')
ridge_grid.fit(X_scaled, y)
ridge_best = ridge_grid.best_estimator_

# Lasso
lasso_params = {'alpha': [0.001, 0.01, 0.1, 1, 10]}
lasso_grid = GridSearchCV(Lasso(max_iter=5000), lasso_params, cv=5, scoring='neg_mean_squared_error')
lasso_grid.fit(X_scaled, y)
lasso_best = lasso_grid.best_estimator_

# SVR
svr_params = {'C': [0.1, 1, 10], 'gamma': ['scale', 'auto'], 'kernel': ['rbf']}
svr_grid = GridSearchCV(SVR(), svr_params, cv=5, scoring='neg_mean_squared_error')
svr_grid.fit(X_scaled, y)
svr_best = svr_grid.best_estimator_

# Árbol de Decisión
tree_params = {'max_depth': [3, 5, 10, None]}
tree_grid = GridSearchCV(DecisionTreeRegressor(random_state=42), tree_params, cv=5, scoring='neg_mean_squared_error')
tree_grid.fit(X_scaled, y)
tree_best = tree_grid.best_estimator_

# Graficar valores reales vs estimados
fig, ax = plt.subplots(figsize=(10, 6))
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    ax.scatter(y_test, y_pred, label=name, alpha=0.5)

ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--k')
ax.set_xlabel('Valor Real')
ax.set_ylabel('Valor Estimado')
ax.set_title('Comparación Valor Real vs Estimado')
ax.legend()
plt.show()

"""
### Preguntas Finales

**¿Se presentó el fenómeno de sobreajuste en los modelos entrenados?**

Sí, se observó sobreajuste especialmente en el Árbol de Decisión y SVR, con un R² alto en entrenamiento y menor en test.

**¿El dataset presenta valores atípicos (outliers)? ¿Cómo se identificaron?**

Sí, usando boxplots. No fueron eliminados, ya que representan datos reales y se decidió mantenerlos tras evaluar su impacto.

**¿Qué transformaciones o adiciones se realizaron a las variables?**

Se aplicó estandarización y selección de hiperparámetros para mejorar la generalización.

**¿Fue necesario eliminar outliers? ¿Por qué sí o por qué no?**

No fue necesario eliminarlos porque los modelos regularizados y SVR pudieron manejarlos de manera razonable.

**¿Cuál fue el modelo de mejor rendimiento y por qué?**

El modelo Ridge ofreció el mejor equilibrio entre sesgo y varianza, con un buen desempeño en datos no vistos.
"""